{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8c5672-f7a7-4af2-a83c-ab7be2003a9e",
   "metadata": {},
   "source": [
    "# Creating Models for San Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b92f55f-c3ad-4c2e-ac94-44149c5faede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>936.000000</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.503205</td>\n",
       "      <td>0.057925</td>\n",
       "      <td>0.067469</td>\n",
       "      <td>0.177655</td>\n",
       "      <td>0.165956</td>\n",
       "      <td>78.568181</td>\n",
       "      <td>16.552409</td>\n",
       "      <td>27.006528</td>\n",
       "      <td>6.757373</td>\n",
       "      <td>31.607957</td>\n",
       "      <td>22.600645</td>\n",
       "      <td>26.785484</td>\n",
       "      <td>34.180556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.021909</td>\n",
       "      <td>0.107153</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.057166</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>3.389488</td>\n",
       "      <td>1.560923</td>\n",
       "      <td>1.415473</td>\n",
       "      <td>0.835993</td>\n",
       "      <td>1.717297</td>\n",
       "      <td>1.506277</td>\n",
       "      <td>29.325811</td>\n",
       "      <td>51.381372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456100</td>\n",
       "      <td>-0.015533</td>\n",
       "      <td>-0.063457</td>\n",
       "      <td>66.735714</td>\n",
       "      <td>11.715714</td>\n",
       "      <td>22.842857</td>\n",
       "      <td>4.528571</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.139283</td>\n",
       "      <td>0.129157</td>\n",
       "      <td>76.246071</td>\n",
       "      <td>15.236429</td>\n",
       "      <td>25.842857</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.068075</td>\n",
       "      <td>0.177186</td>\n",
       "      <td>0.165971</td>\n",
       "      <td>78.667857</td>\n",
       "      <td>16.845714</td>\n",
       "      <td>27.228571</td>\n",
       "      <td>6.757143</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.250000</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.212557</td>\n",
       "      <td>0.202771</td>\n",
       "      <td>80.963214</td>\n",
       "      <td>17.858571</td>\n",
       "      <td>28.185714</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>35.450000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.393129</td>\n",
       "      <td>0.381420</td>\n",
       "      <td>87.575714</td>\n",
       "      <td>19.440000</td>\n",
       "      <td>30.071429</td>\n",
       "      <td>9.914286</td>\n",
       "      <td>35.600000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>305.900000</td>\n",
       "      <td>461.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weekofyear     ndvi_ne     ndvi_nw     ndvi_se     ndvi_sw  \\\n",
       "count  936.000000  745.000000  887.000000  917.000000  917.000000   \n",
       "mean    26.503205    0.057925    0.067469    0.177655    0.165956   \n",
       "std     15.021909    0.107153    0.092479    0.057166    0.056073   \n",
       "min      1.000000   -0.406250   -0.456100   -0.015533   -0.063457   \n",
       "25%     13.750000    0.004500    0.016425    0.139283    0.129157   \n",
       "50%     26.500000    0.057700    0.068075    0.177186    0.165971   \n",
       "75%     39.250000    0.111100    0.115200    0.212557    0.202771   \n",
       "max     53.000000    0.493400    0.437100    0.393129    0.381420   \n",
       "\n",
       "       reanalysis_relative_humidity_percent  \\\n",
       "count                            930.000000   \n",
       "mean                              78.568181   \n",
       "std                                3.389488   \n",
       "min                               66.735714   \n",
       "25%                               76.246071   \n",
       "50%                               78.667857   \n",
       "75%                               80.963214   \n",
       "max                               87.575714   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "count                             930.000000          930.000000   \n",
       "mean                               16.552409           27.006528   \n",
       "std                                 1.560923            1.415473   \n",
       "min                                11.715714           22.842857   \n",
       "25%                                15.236429           25.842857   \n",
       "50%                                16.845714           27.228571   \n",
       "75%                                17.858571           28.185714   \n",
       "max                                19.440000           30.071429   \n",
       "\n",
       "       station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "count               930.000000          930.000000          930.000000   \n",
       "mean                  6.757373           31.607957           22.600645   \n",
       "std                   0.835993            1.717297            1.506277   \n",
       "min                   4.528571           26.700000           17.800000   \n",
       "25%                   6.200000           30.600000           21.700000   \n",
       "50%                   6.757143           31.700000           22.800000   \n",
       "75%                   7.285714           32.800000           23.900000   \n",
       "max                   9.914286           35.600000           25.600000   \n",
       "\n",
       "       station_precip_mm  total_cases  \n",
       "count         930.000000   936.000000  \n",
       "mean           26.785484    34.180556  \n",
       "std            29.325811    51.381372  \n",
       "min             0.000000     0.000000  \n",
       "25%             6.825000     9.000000  \n",
       "50%            17.750000    19.000000  \n",
       "75%            35.450000    37.000000  \n",
       "max           305.900000   461.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import  mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "sj_new = pd.read_csv(\"./sj_less_columns.csv\")\n",
    "sj_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123c61ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.01890</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>78.781429</td>\n",
       "      <td>15.918571</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.057143</td>\n",
       "      <td>33.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.01800</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>0.082043</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>78.230000</td>\n",
       "      <td>15.791429</td>\n",
       "      <td>26.071429</td>\n",
       "      <td>5.557143</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.00150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>78.270000</td>\n",
       "      <td>16.674286</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.019867</td>\n",
       "      <td>0.124329</td>\n",
       "      <td>0.125686</td>\n",
       "      <td>73.015714</td>\n",
       "      <td>15.775714</td>\n",
       "      <td>28.057143</td>\n",
       "      <td>6.271429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.05680</td>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.062267</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>74.084286</td>\n",
       "      <td>16.137143</td>\n",
       "      <td>27.614286</td>\n",
       "      <td>7.085714</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>84.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.08740</td>\n",
       "      <td>-0.016183</td>\n",
       "      <td>0.156343</td>\n",
       "      <td>0.105186</td>\n",
       "      <td>78.780000</td>\n",
       "      <td>15.985714</td>\n",
       "      <td>27.542857</td>\n",
       "      <td>7.942857</td>\n",
       "      <td>33.9</td>\n",
       "      <td>22.8</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>-0.077833</td>\n",
       "      <td>0.204171</td>\n",
       "      <td>0.178914</td>\n",
       "      <td>81.650000</td>\n",
       "      <td>15.881429</td>\n",
       "      <td>26.642857</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.11760</td>\n",
       "      <td>-0.008200</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.170429</td>\n",
       "      <td>78.285714</td>\n",
       "      <td>16.212857</td>\n",
       "      <td>27.914286</td>\n",
       "      <td>8.114286</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>16</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>77.674286</td>\n",
       "      <td>15.965714</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>6.942857</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.9</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.08730</td>\n",
       "      <td>-0.048667</td>\n",
       "      <td>0.129814</td>\n",
       "      <td>0.117671</td>\n",
       "      <td>79.045714</td>\n",
       "      <td>15.451429</td>\n",
       "      <td>26.442857</td>\n",
       "      <td>6.742857</td>\n",
       "      <td>31.1</td>\n",
       "      <td>21.7</td>\n",
       "      <td>47.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weekofyear  ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0            18 -0.01890 -0.018900  0.102729  0.091200   \n",
       "1            19 -0.01800 -0.012400  0.082043  0.072314   \n",
       "2            20 -0.00150       NaN  0.151083  0.091529   \n",
       "3            21      NaN -0.019867  0.124329  0.125686   \n",
       "4            22  0.05680  0.039833  0.062267  0.075914   \n",
       "..          ...      ...       ...       ...       ...   \n",
       "255          13 -0.08740 -0.016183  0.156343  0.105186   \n",
       "256          14 -0.20325 -0.077833  0.204171  0.178914   \n",
       "257          15 -0.11760 -0.008200  0.192700  0.170429   \n",
       "258          16  0.08275  0.031200  0.135014  0.074857   \n",
       "259          17 -0.08730 -0.048667  0.129814  0.117671   \n",
       "\n",
       "     reanalysis_relative_humidity_percent  \\\n",
       "0                               78.781429   \n",
       "1                               78.230000   \n",
       "2                               78.270000   \n",
       "3                               73.015714   \n",
       "4                               74.084286   \n",
       "..                                    ...   \n",
       "255                             78.780000   \n",
       "256                             81.650000   \n",
       "257                             78.285714   \n",
       "258                             77.674286   \n",
       "259                             79.045714   \n",
       "\n",
       "     reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "0                                15.918571           26.528571   \n",
       "1                                15.791429           26.071429   \n",
       "2                                16.674286           27.928571   \n",
       "3                                15.775714           28.057143   \n",
       "4                                16.137143           27.614286   \n",
       "..                                     ...                 ...   \n",
       "255                              15.985714           27.542857   \n",
       "256                              15.881429           26.642857   \n",
       "257                              16.212857           27.914286   \n",
       "258                              15.965714           27.728571   \n",
       "259                              15.451429           26.442857   \n",
       "\n",
       "     station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "0                   7.057143                33.3                21.7   \n",
       "1                   5.557143                30.0                22.2   \n",
       "2                   7.785714                32.8                22.8   \n",
       "3                   6.271429                33.3                24.4   \n",
       "4                   7.085714                33.3                23.3   \n",
       "..                       ...                 ...                 ...   \n",
       "255                 7.942857                33.9                22.8   \n",
       "256                 6.642857                33.3                22.8   \n",
       "257                 8.114286                32.8                23.3   \n",
       "258                 6.942857                31.7                23.9   \n",
       "259                 6.742857                31.1                21.7   \n",
       "\n",
       "     station_precip_mm  \n",
       "0                 75.2  \n",
       "1                 34.3  \n",
       "2                  3.0  \n",
       "3                  0.3  \n",
       "4                 84.1  \n",
       "..                 ...  \n",
       "255                3.5  \n",
       "256               17.6  \n",
       "257                9.4  \n",
       "258               22.9  \n",
       "259               47.5  \n",
       "\n",
       "[260 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test = pd.read_csv(\"./sj_test_less_columns.csv\")\n",
    "Year = sj_test['year']\n",
    "sj_test.drop(['year'], axis=1, inplace=True)\n",
    "sj_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e4a72-d0d4-4b20-b911-3eaf4ead3d10",
   "metadata": {},
   "source": [
    "The following cell replaces the NaN values with the mean of the cells' values above and below the cell with NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a38738-3fa4-4569-b3cb-b43f6954b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assume 'df' is a dataframe containing NaN values in multiple columns\n",
    "for col in sj_new.columns:\n",
    "    temp = sj_new[col].to_numpy()  # convert the column to a numpy array for faster processing\n",
    "    \n",
    "    # fill NaN values with the mean of the previous and next valid values\n",
    "    mask = sj_new[col].isnull()\n",
    "    temp[mask] = pd.Series(temp).fillna(method='ffill').add(pd.Series(temp).fillna(method='bfill')).div(2).values[mask]\n",
    "\n",
    "    # assign the updated values back to the dataframe column\n",
    "    sj_new[col] = pd.Series(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df48468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 'df' is a dataframe containing NaN values in multiple columns\n",
    "for col in sj_test.columns:\n",
    "    temp = sj_test[col].to_numpy()  # convert the column to a numpy array for faster processing\n",
    "    \n",
    "    # fill NaN values with the mean of the previous and next valid values\n",
    "    mask = sj_test[col].isnull()\n",
    "    temp[mask] = pd.Series(temp).fillna(method='ffill').add(pd.Series(temp).fillna(method='bfill')).div(2).values[mask]\n",
    "\n",
    "    # assign the updated values back to the dataframe column\n",
    "    sj_test[col] = pd.Series(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db6c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "163.375\n"
     ]
    }
   ],
   "source": [
    "threshold_prec = sj_new['station_precip_mm'].quantile(0.975)\n",
    "threshold_cases = sj_new['total_cases'].quantile(0.975)\n",
    "\n",
    "# Applying the thresholds into the df\n",
    "sj_new.loc[sj_new['station_precip_mm'] > threshold_prec, 'station_precip_mm'] = threshold_prec\n",
    "sj_new.loc[sj_new['total_cases'] > threshold_cases, 'total_cases'] = threshold_cases\n",
    "\n",
    "min_val = sj_new['total_cases'].min()\n",
    "max_val = sj_new['total_cases'].max()\n",
    "\n",
    "print(min_val)\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d824d4ed-3d41-4adc-9f0b-7668e03b391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_new['weekofyear'] =  sj_new['weekofyear'] / 53\n",
    "sj_new['reanalysis_relative_humidity_percent'] = sj_new['reanalysis_relative_humidity_percent'] / 100\n",
    "sj_new['reanalysis_specific_humidity_g_per_kg'] =  sj_new['reanalysis_specific_humidity_g_per_kg'] / 20\n",
    "\n",
    "# select columns to normalize with StandardScaler and MinMaxScaler\n",
    "#columns_minmax = ['station_precip_mm', 'total_cases']\n",
    "columns_standard = ['station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c', 'station_min_temp_c']\n",
    "\n",
    "# normalize columns with StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_standard.fit(sj_new[columns_standard])\n",
    "\n",
    "sj_new[columns_standard] = scaler_standard.transform(sj_new[columns_standard])\n",
    "# normalize columns with MinMaxScaler\n",
    "scaler_minmax1 = MinMaxScaler()\n",
    "scaler_minmax2 = MinMaxScaler()\n",
    "\n",
    "scaler_minmax1.fit(sj_new[['station_precip_mm']])\n",
    "scaler_minmax2.fit(sj_new[['total_cases']])\n",
    "\n",
    "sj_new['station_precip_mm'] = scaler_minmax1.transform(sj_new[['station_precip_mm']])\n",
    "sj_new['total_cases'] = scaler_minmax2.transform(sj_new[['total_cases']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832d65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the thresholds into the df\n",
    "sj_test.loc[sj_test['station_precip_mm'] > threshold_prec, 'station_precip_mm'] = threshold_prec\n",
    "\n",
    "sj_test['weekofyear'] =  sj_test['weekofyear'] / 53\n",
    "sj_test['reanalysis_relative_humidity_percent'] = sj_test['reanalysis_relative_humidity_percent'] / 100\n",
    "sj_test['reanalysis_specific_humidity_g_per_kg'] =  sj_test['reanalysis_specific_humidity_g_per_kg'] / 20\n",
    "\n",
    "\n",
    "\n",
    "# select columns to normalize with StandardScaler and MinMaxScaler\n",
    "columns_minmax = ['station_precip_mm']\n",
    "columns_standard = ['station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c', 'station_min_temp_c']\n",
    "\n",
    "# normalize columns with StandardScaler\n",
    "\n",
    "sj_test[columns_standard] = scaler_standard.transform(sj_test[columns_standard])\n",
    "\n",
    "sj_test['station_precip_mm'] = scaler_minmax1.transform(sj_test[['station_precip_mm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352f3076-6aea-4998-b217-48d9bfc66fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.177095</td>\n",
       "      <td>0.153210</td>\n",
       "      <td>0.781830</td>\n",
       "      <td>0.837076</td>\n",
       "      <td>0.186241</td>\n",
       "      <td>-0.719532</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.332724</td>\n",
       "      <td>0.315712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.283848</td>\n",
       "      <td>0.127483</td>\n",
       "      <td>0.086986</td>\n",
       "      <td>0.066747</td>\n",
       "      <td>0.055021</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.084058</td>\n",
       "      <td>1.004820</td>\n",
       "      <td>0.821357</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.997418</td>\n",
       "      <td>0.294046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.463400</td>\n",
       "      <td>-0.211800</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>0.626857</td>\n",
       "      <td>-2.007951</td>\n",
       "      <td>-3.245826</td>\n",
       "      <td>-2.557870</td>\n",
       "      <td>-1.723902</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.259434</td>\n",
       "      <td>-0.044687</td>\n",
       "      <td>-0.010650</td>\n",
       "      <td>0.131929</td>\n",
       "      <td>0.116486</td>\n",
       "      <td>0.760379</td>\n",
       "      <td>0.767929</td>\n",
       "      <td>-0.659932</td>\n",
       "      <td>-1.261787</td>\n",
       "      <td>-0.666904</td>\n",
       "      <td>-0.594043</td>\n",
       "      <td>0.070751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.031960</td>\n",
       "      <td>0.169411</td>\n",
       "      <td>0.148580</td>\n",
       "      <td>0.783357</td>\n",
       "      <td>0.851643</td>\n",
       "      <td>0.289236</td>\n",
       "      <td>-0.688811</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>0.303199</td>\n",
       "      <td>0.217922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.218082</td>\n",
       "      <td>0.191275</td>\n",
       "      <td>0.804214</td>\n",
       "      <td>0.909107</td>\n",
       "      <td>1.071794</td>\n",
       "      <td>-0.201353</td>\n",
       "      <td>0.700409</td>\n",
       "      <td>1.200440</td>\n",
       "      <td>0.475780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.385383</td>\n",
       "      <td>0.318129</td>\n",
       "      <td>0.867814</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>2.313790</td>\n",
       "      <td>1.970827</td>\n",
       "      <td>1.980448</td>\n",
       "      <td>2.729074</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weekofyear     ndvi_ne     ndvi_nw     ndvi_se     ndvi_sw  \\\n",
       "count  260.000000  260.000000  260.000000  260.000000  260.000000   \n",
       "mean     0.500073    0.024490    0.037349    0.177095    0.153210   \n",
       "std      0.283848    0.127483    0.086986    0.066747    0.055021   \n",
       "min      0.018868   -0.463400   -0.211800    0.006200   -0.014671   \n",
       "25%      0.259434   -0.044687   -0.010650    0.131929    0.116486   \n",
       "50%      0.500000    0.014100    0.031960    0.169411    0.148580   \n",
       "75%      0.740566    0.079600    0.078100    0.218082    0.191275   \n",
       "max      1.000000    0.500400    0.649000    0.385383    0.318129   \n",
       "\n",
       "       reanalysis_relative_humidity_percent  \\\n",
       "count                            260.000000   \n",
       "mean                               0.781830   \n",
       "std                                0.034014   \n",
       "min                                0.649200   \n",
       "25%                                0.760379   \n",
       "50%                                0.783357   \n",
       "75%                                0.804214   \n",
       "max                                0.867814   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "count                             260.000000          260.000000   \n",
       "mean                                0.837076            0.186241   \n",
       "std                                 0.084058            1.004820   \n",
       "min                                 0.626857           -2.007951   \n",
       "25%                                 0.767929           -0.659932   \n",
       "50%                                 0.851643            0.289236   \n",
       "75%                                 0.909107            1.071794   \n",
       "max                                 0.967000            2.313790   \n",
       "\n",
       "       station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "count               260.000000          260.000000          260.000000   \n",
       "mean                 -0.719532            0.040921            0.332724   \n",
       "std                   0.821357            0.994621            0.997418   \n",
       "min                  -3.245826           -2.557870           -1.723902   \n",
       "25%                  -1.261787           -0.666904           -0.594043   \n",
       "50%                  -0.688811            0.060390            0.303199   \n",
       "75%                  -0.201353            0.700409            1.200440   \n",
       "max                   1.970827            1.980448            2.729074   \n",
       "\n",
       "       station_precip_mm  \n",
       "count         260.000000  \n",
       "mean            0.315712  \n",
       "std             0.294046  \n",
       "min             0.000000  \n",
       "25%             0.070751  \n",
       "50%             0.217922  \n",
       "75%             0.475780  \n",
       "max             1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd61483-9e35-4afe-9979-18e8fbb7c737",
   "metadata": {},
   "source": [
    "## Selecting target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d207ff6-a146-488c-ab8e-2bdd5bb0dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (936, 12)\n",
      "Shape of y_train: (936,)\n"
     ]
    }
   ],
   "source": [
    "X_sj = sj_new.drop(columns = \"total_cases\")\n",
    "Y_sj = sj_new.loc[:, \"total_cases\"]\n",
    "\n",
    "\n",
    "X_train = X_sj\n",
    "Y_train = Y_sj\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X_sj, Y_sj, test_size=0.20)\n",
    "print(\"Shape of x_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", Y_train.shape)\n",
    "# print(\"Shape of x_test:\", X_test.shape)\n",
    "# print(\"Shape of y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d70230-f564-4a30-9440-02f2463ee877",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Choice\n",
    "## Linear Model Regressor (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7649f147-8ad0-46b8-988c-a444328bcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.195\n",
      "MAE Train: 0.136\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train, Y_train)\n",
    "# lr_model_pred_test = lr_model.predict(X_test)\n",
    "lr_model_pred_train = lr_model.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "rmse_lr_train = mean_squared_error(Y_train, lr_model_pred_train, squared=False) \n",
    "mae_lr_train = mean_absolute_error(Y_train, lr_model_pred_train)\n",
    "\n",
    "# rmse_lr_test = mean_squared_error(Y_test, lr_model_pred_test, squared=False) \n",
    "# mae_lr_test = mean_absolute_error(Y_test, lr_model_pred_test)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_lr_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_lr_train))\n",
    "\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_lr_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_lr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a15a0-c515-43c2-97e1-fb6036cdd915",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce332567-6108-47fb-89c0-935ed731cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_model = DecisionTreeRegressor()\n",
    "# # create a grid search object\n",
    "\n",
    "# param_grid = {\n",
    "#     \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(dt_model, param_grid, cv=5)\n",
    "\n",
    "# # fit the grid search object to the training data\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # create a new random forest regressor with the best hyperparameters\n",
    "# dt_model = DecisionTreeRegressor(max_depth=best_params['max_depth'], criterion=best_params[\"criterion\"])\n",
    "\n",
    "# # fit the model to the training data\n",
    "# dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# # generate predictions on the training data\n",
    "# dt_train_pred = dt_model.predict(X_train)\n",
    "\n",
    "# # evaluate the model on the test data\n",
    "# dt_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# rmse_dt = mean_squared_error(Y_test, dt_test_pred, squared=False)\n",
    "# mae_dt = mean_absolute_error(Y_test, dt_test_pred)\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"RMSE: {:.3f}\".format(rmse_dt))\n",
    "# print(\"MAE: {:.3f}\".format(mae_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf9025d-0746-40b8-b64c-607ba203e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.136\n",
      "MAE Train: 0.091\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeRegressor(criterion='squared_error', max_depth=5)\n",
    "\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# generate predictions on the training data\n",
    "dt_train_pred = dt_model.predict(X_train)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "# dt_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "rmse_dt_train = mean_squared_error(Y_train, dt_train_pred, squared=False)\n",
    "mae_dt_train = mean_absolute_error(Y_train, dt_train_pred)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_dt_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_dt_train))\n",
    "\n",
    "# rmse_dt_test = mean_squared_error(Y_test, dt_test_pred, squared=False)\n",
    "# mae_dt_test = mean_absolute_error(Y_test, dt_test_pred)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_dt_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_dt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884ad4b-89fa-4271-af1b-81275ddd4932",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bec2a96-c67b-4e0e-96e7-d262092ac9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a random forest regressor object\n",
    "# rf_model = RandomForestRegressor()\n",
    "\n",
    "# # define the grid search parameters\n",
    "# param_grid = {\n",
    "#     \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "\n",
    "# # create a grid search object\n",
    "# grid_search = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "\n",
    "# # fit the grid search object to the training data\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # create a new random forest regressor with the best hyperparameters\n",
    "# rf_model = RandomForestRegressor(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], criterion=best_params[\"criterion\"])\n",
    "\n",
    "# # fit the model to the training data\n",
    "# rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# # generate predictions on the training data\n",
    "# rf_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# # evaluate the model on the test data\n",
    "# rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# rmse_rf = mean_squared_error(Y_test, rf_test_pred, squared=False)\n",
    "# mae_rf = mean_absolute_error(Y_test, rf_test_pred)\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"RMSE: {:.3f}\".format(rmse_rf))\n",
    "# print(\"MAE: {:.3f}\".format(mae_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d66d18-f993-4272-8a62-55d1fd8f3aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.077\n",
      "MAE Train: 0.055\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(criterion='squared_error', n_estimators=500, max_depth=10)\n",
    "# fit the model to the training data\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# generate predictions on the training data\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "# rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse_rf_train = mean_squared_error(Y_train, rf_train_pred, squared=False)\n",
    "mae_rf_train = mean_absolute_error(Y_train, rf_train_pred)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_rf_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_rf_train))\n",
    "\n",
    "# rmse_rf_test = mean_squared_error(Y_test, rf_test_pred, squared=False)\n",
    "# mae_rf_test = mean_absolute_error(Y_test, rf_test_pred)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_rf_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e73762-58f9-4db8-9b55-37668cf45ab9",
   "metadata": {},
   "source": [
    "## Neural Network Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0ff8ebc-f302-4aa8-b58c-ebaf53f419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hyperparameters to search over\n",
    "# NN_model = MLPRegressor()\n",
    "# params = {\n",
    "#     'hidden_layer_sizes': [(64,), (32, 16), (64, 32, 16)],\n",
    "#     'max_iter': [500, 1000, 2000],\n",
    "#     'activation': ['relu', 'tanh', 'logistic']\n",
    "# }\n",
    "\n",
    "# # Perform a grid search over the hyperparameters\n",
    "# grid_search = GridSearchCV(NN_model, param_grid=params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Print the best hyperparameters and the associated mean test score\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# # Use the best model to make predictions on the training and testing data\n",
    "# best_model = grid_search.best_estimator_\n",
    "# Y_pred_train = best_model.predict(X_train)\n",
    "# Y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# # Compute the RMSE and MAE for the training and testing data\n",
    "# rmse_train = mean_squared_error(Y_train, Y_pred_train, squared=False)\n",
    "# mae_train = mean_absolute_error(Y_train, Y_pred_train)\n",
    "# print(\"RMSE Train: {:.3f}\".format(rmse_train))\n",
    "# print(\"MAE Train: {:.3f}\".format(mae_train))\n",
    "\n",
    "# rmse_test = mean_squared_error(Y_test, Y_pred_test, squared=False)\n",
    "# mae_test = mean_absolute_error(Y_test, Y_pred_test)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e80cda3c-f4f6-4c40-a52d-ed0f39b03d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.153\n",
      "MAE Train: 0.103\n"
     ]
    }
   ],
   "source": [
    "NN_model = MLPRegressor(activation='relu', hidden_layer_sizes=(64,32,16), max_iter=200, alpha = 0.0001)\n",
    "\n",
    "# Train the model on the training data\n",
    "NN_model.fit(X_train, Y_train)\n",
    "\n",
    "# Test the model on the testing data and print the accuracy score\n",
    "Y_pred_NN_train = NN_model.predict(X_train)\n",
    "# Y_pred_NN_test = NN_model.predict(X_test)\n",
    "\n",
    "rmse_train_nn = mean_squared_error(Y_train, Y_pred_NN_train, squared=False)\n",
    "mae_train_nn = mean_absolute_error(Y_train, Y_pred_NN_train)\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_train_nn))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_train_nn))\n",
    "\n",
    "# rmse_test_nn = mean_squared_error(Y_test, Y_pred_NN_test, squared=False)\n",
    "# mae_test_nn = mean_absolute_error(Y_test, Y_pred_NN_test)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_test_nn))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d94370-14cc-46fe-af5b-857449e30bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 12))\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# ax.minorticks_on()\n",
    "# ax.xaxis.set_ticks_position(\"both\")\n",
    "# ax.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "# plt.title(\"Loss Curve\", fontsize=12)\n",
    "# plt.xlabel('Iterations', fontsize = 12)\n",
    "# plt.ylabel('Loss', fontsize = 12)\n",
    "# plt.plot(NN_model.loss_curve_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d33d32-335f-44b3-a9fa-39d7991a0b87",
   "metadata": {},
   "source": [
    "## eXtreme Gradient Boosting (XGB) Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cdadf69-804f-423f-97d6-6d5c32aef3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# #Define the XGBoost model\n",
    "# xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb_model,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, Y_train, early_stopping_rounds=10, eval_set=[(X_test, Y_test)], verbose=False)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding RMSE\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# y_train_pred = grid_search.predict(X_train)\n",
    "# rmse_train = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "# print(f'RMSE_train: {rmse_train:.2f}')\n",
    "\n",
    "# test_predictions = grid_search.predict(X_test)\n",
    "# rmse_test = mean_squared_error(Y_test, test_predictions, squared=False)\n",
    "# print(f'RMSE_test: {rmse_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9962b871-3b16-4dbd-80ea-3640d4103335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.023\n",
      "MAE Train: 0.017\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, colsample_bytree = 0.7, max_depth=9)\n",
    "\n",
    "xgb_model.fit(X_train, Y_train, verbose=False)\n",
    "\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "rmse_train_xgb = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "mae_train_xgb = mean_absolute_error(Y_train, y_train_pred)\n",
    "print(f'RMSE Train: {rmse_train_xgb:.3f}')\n",
    "print(f'MAE Train: {mae_train_xgb:.3f}')\n",
    "\n",
    "# y_test_pred = xgb_model.predict(X_test)\n",
    "# rmse_test_xgb = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgb = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgb:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgb:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3da630-765b-4738-9994-af2d5b3dba1e",
   "metadata": {},
   "source": [
    "# XGB with Regularization Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b6ab97c-4178-478d-83f6-1bc6e8c7855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'colsample_bytree': [0.5, 0.8],\n",
    "#     'max_depth': [4, 6, 8],\n",
    "#     'alpha': [0.1, 0.5],\n",
    "#     'min_child_weight': [1, 3],\n",
    "#     'gamma': [0.1, 0.5],\n",
    "#     'subsample': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Create the XGBoost regressor\n",
    "# xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best model from grid search\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Fit the best model to the training data\n",
    "# best_model.fit(X_train, Y_train, early_stopping_rounds=10, eval_set=[(X_test, Y_test)], verbose=False)\n",
    "\n",
    "# # Predict on training data\n",
    "# y_train_pred = best_model.predict(X_train)\n",
    "# rmse_train_xgbreg = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "# mae_train_xgbreg = mean_absolute_error(Y_train, y_train_pred)\n",
    "# print(f'RMSE Train: {rmse_train_xgbreg:.3f}')\n",
    "# print(f'MAE Train: {mae_train_xgbreg:.3f}')\n",
    "\n",
    "# # Predict on test data\n",
    "# y_test_pred = best_model.predict(X_test)\n",
    "# rmse_test_xgbreg = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgbreg = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgbreg:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgbreg:.3f}')\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "419f83fa-2799-41bf-9271-5cc9914e8ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.089\n",
      "MAE Train: 0.065\n"
     ]
    }
   ],
   "source": [
    "# Create the XGBoost regressor\n",
    "xgb_model_reg = xgb.XGBRegressor(alpha = 0.1, colsample_bytree=0.8, gamma=0.1, learning_rate= 0.05, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.8)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "xgb_model_reg.fit(X_train, Y_train, verbose=False)\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = xgb_model_reg.predict(X_train)\n",
    "rmse_train_xgbreg = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "mae_train_xgbreg = mean_absolute_error(Y_train, y_train_pred)\n",
    "print(f'RMSE Train: {rmse_train_xgbreg:.3f}')\n",
    "print(f'MAE Train: {mae_train_xgbreg:.3f}')\n",
    "\n",
    "# Predict on test data\n",
    "# y_test_pred = xgb_model.predict(X_test)\n",
    "# rmse_test_xgbreg = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgbreg = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgbreg:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgbreg:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ef547-bd8f-4a24-8575-d50247706ccd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c50725-2572-4f31-924c-748a91cba3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the SVM model\n",
    "# svm_model = SVR(kernel='rbf')\n",
    "\n",
    "# # Define the parameter grid for grid search\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'epsilon': [0.01, 0.1, 1]\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best model from grid search\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Train the model on the training data\n",
    "# best_model.fit(X_train, Y_train)\n",
    "\n",
    "# # Make predictions on the train set\n",
    "# y_pred = best_model.predict(X_train)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_train_svm = mean_absolute_error(Y_train, y_pred)\n",
    "\n",
    "# # Calculate the RMSE\n",
    "# rmse_train_svm = np.sqrt(mean_squared_error(Y_train, y_pred))\n",
    "\n",
    "# print(f'RMSE Train: {rmse_train_svm:.3f}')\n",
    "# print(f'MAE Train: {mae_train_svm:.3f}')\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_test_svm = mean_absolute_error(Y_test, test_predictions)\n",
    "\n",
    "# # Calculate the RMSE\n",
    "# rmse_test_svm = np.sqrt(mean_squared_error(Y_test, test_predictions))\n",
    "\n",
    "# print(f'RMSE Test: {rmse_test_svm:.3f}')\n",
    "# print(f'MAE Test: {mae_test_svm:.3f}')\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters:\")\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3fcfc7-9275-4b02-983b-aa915d52bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.181\n",
      "MAE Train: 0.115\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = SVR(kernel='rbf', C=10, gamma='auto', epsilon=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "y_pred = svm_model.predict(X_train)\n",
    "\n",
    "# Calculate the MAE\n",
    "mae_train_svm = mean_absolute_error(Y_train, y_pred)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse_train_svm = np.sqrt(mean_squared_error(Y_train, y_pred))\n",
    "\n",
    "print(f'RMSE Train: {rmse_train_svm:.3f}')\n",
    "print(f'MAE Train: {mae_train_svm:.3f}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "# test_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_test_svm = mean_absolute_error(Y_test, test_predictions)\n",
    "# # Calculate the RMSE\n",
    "# rmse_test_svm = np.sqrt(mean_squared_error(Y_test, test_predictions))\n",
    "\n",
    "# print(f'RMSE Test: {rmse_test_svm:.3f}')\n",
    "# print(f'MAE Test: {mae_test_svm:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594d536-7735-4d3b-930c-8174ee69c8ac",
   "metadata": {},
   "source": [
    "## Plotting of Top Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde06a7-0621-46f9-8299-cf650bd87694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_knn_train = 0.18627\n",
    "# mae_knn_train = 0.0979\n",
    "# rmse_knn_test = 0.2096\n",
    "# mae_knn_test = 0.1142\n",
    "\n",
    "# rmse_adaboost_train = 0.1808\n",
    "# mae_adaboost_train = 0.13025\n",
    "# rmse_adaboost_test = 0.1997\n",
    "# mae_adaboost_test = 0.13496\n",
    "\n",
    "# rmse_train_values = [rmse_lr_train, rmse_dt_train, rmse_rf_train , rmse_train_nn, rmse_knn_train, rmse_adaboost_train, rmse_train_xgb, rmse_train_xgbreg, rmse_train_svm]\n",
    "# rmse_test_values = [rmse_lr_test, rmse_dt_test, rmse_rf_test , rmse_test_nn, rmse_knn_test, rmse_adaboost_test, rmse_test_xgb, rmse_test_xgbreg, rmse_test_svm]\n",
    "\n",
    "# mae_train_values = [mae_lr_train, mae_dt_train, mae_rf_train , mae_train_nn, mae_knn_train, mae_adaboost_train, mae_train_xgb, mae_train_xgbreg, mae_train_svm]\n",
    "# mae_test_values = [mae_lr_test, mae_dt_test, mae_rf_test , mae_test_nn, mae_knn_test, mae_adaboost_test, mae_test_xgb, mae_test_xgbreg, mae_test_svm]\n",
    "\n",
    "# model_labels = ['Linear Model', 'Decision Tree', 'Random Forest', 'Neural Network','Nueral Network (Keras)', \"Adaboost\", 'XGB', 'Reg. XGB', \"SVM\"]\n",
    "\n",
    "# train_positions = np.arange(len(model_labels))\n",
    "# test_positions = train_positions + 0.2  # Add a small offset to separate the bars\n",
    "\n",
    "# # Set the figure size\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# ax1 = plt.subplot(1, 2, 1)\n",
    "# ax1.bar(train_positions, rmse_train_values, color='lightcoral', width=0.2, label='Train');\n",
    "# ax1.bar(test_positions, rmse_test_values, color='firebrick', width=0.2, label='Test');\n",
    "# ax1.set_title('RMSE of Train and Test Sets', fontsize=12)\n",
    "# ax1.set_ylabel('RMSE', fontsize=12)\n",
    "# ax1.set_ylim(0,0.30)\n",
    "# ax1.set_xticks(train_positions + 0.1, model_labels, fontsize=12, rotation=45)\n",
    "# ax1.legend(loc=\"best\")\n",
    "# ax1.minorticks_on()\n",
    "# ax1.xaxis.set_ticks_position(\"both\")\n",
    "# ax1.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax1.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "\n",
    "# ax2 = plt.subplot(1, 2, 2)\n",
    "# ax2.bar(train_positions, mae_train_values, color='lightcoral', width=0.2, label='Train');\n",
    "# ax2.bar(test_positions, mae_test_values, color='firebrick', width=0.2, label='Test');\n",
    "# ax2.set_title('MAE of Train and Test Sets', fontsize=12)\n",
    "# ax2.set_ylabel('MAE', fontsize=12)\n",
    "# ax2.set_ylim(0,0.30)\n",
    "# ax2.set_xticks(train_positions + 0.1, model_labels, fontsize=12, rotation=45)\n",
    "# ax2.legend(loc=\"best\")\n",
    "# ax2.minorticks_on()\n",
    "# ax2.xaxis.set_ticks_position(\"both\")\n",
    "# ax2.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax2.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('sj_new_20.png')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39d673-84ac-4d10-baf0-02cfddabdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scatter plot of predicted vs actual values for test data\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# plt.scatter(rf_test_pred, Y_test, color=\"blue\")\n",
    "\n",
    "# slope, intercept = np.polyfit(rf_test_pred, Y_test, 1)\n",
    "# x = np.linspace(min(rf_test_pred), max(rf_test_pred), 100)\n",
    "# y = slope * x + intercept\n",
    "\n",
    "# # create scatter plot of predicted vs actual values for test data\n",
    "# plt.scatter(rf_test_pred, Y_test, color = \"blue\")\n",
    "# plt.plot(x, y, color='red')\n",
    "\n",
    "# plt.title('Random Forest Regression Model', fontsize = 12)\n",
    "# plt.xlabel('Predicted Values', fontsize = 12)\n",
    "# plt.ylabel('Actual Values', fontsize = 12)\n",
    "\n",
    "# ax.minorticks_on()\n",
    "# ax.xaxis.set_ticks_position(\"both\")\n",
    "# ax.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "# plt.tight_layout()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min_val)\n",
    "# print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fe1fc7f-91c4-4080-964c-c88e0f6eeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm_model.predict(sj_test)\n",
    "#predictions = xgb_model_reg.predict(sj_test)\n",
    "#predictions = xgb_model.predict(sj_test)\n",
    "#predictions = rf_model.predict(sj_test)\n",
    "#predictions = NN_model.predict(sj_test)\n",
    "#predictions = lr_model.predict(sj_test)\n",
    "#predictions = dt_model.predict(sj_test)\n",
    "\n",
    "predictions = predictions * (max_val - min_val) + min_val\n",
    "predictions[predictions < 0] = 0\n",
    "#predictions = scaler_minmax2.inverse_transform\n",
    "predictions = predictions.astype(int)\n",
    "week = (sj_test['weekofyear']*53).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc74cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions, columns=[\"total_cases\"])\n",
    "submission.insert(0, 'city', \"sj\")\n",
    "submission.insert(1, 'year', Year)\n",
    "submission.insert(2, 'weekofyear', week)\n",
    "submission.reset_index()\n",
    "submission.to_csv('sj_svm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9de8f899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>sj</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>sj</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>sj</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>sj</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>sj</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear  total_cases\n",
       "0     sj  2008          18           13\n",
       "1     sj  2008          19           14\n",
       "2     sj  2008          20            5\n",
       "3     sj  2008          21           16\n",
       "4     sj  2008          22           22\n",
       "..   ...   ...         ...          ...\n",
       "255   sj  2013          13            3\n",
       "256   sj  2013          14           11\n",
       "257   sj  2013          15            0\n",
       "258   sj  2013          16            9\n",
       "259   sj  2013          17           11\n",
       "\n",
       "[260 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32895a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
