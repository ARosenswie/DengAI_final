{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8c5672-f7a7-4af2-a83c-ab7be2003a9e",
   "metadata": {},
   "source": [
    "# Creating Models for Iquitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b92f55f-c3ad-4c2e-ac94-44149c5faede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>516.000000</td>\n",
       "      <td>516.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.503846</td>\n",
       "      <td>0.263869</td>\n",
       "      <td>0.238783</td>\n",
       "      <td>0.250126</td>\n",
       "      <td>0.266779</td>\n",
       "      <td>88.639117</td>\n",
       "      <td>17.096110</td>\n",
       "      <td>27.530933</td>\n",
       "      <td>10.566197</td>\n",
       "      <td>34.004545</td>\n",
       "      <td>21.196680</td>\n",
       "      <td>62.467262</td>\n",
       "      <td>7.565385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.029450</td>\n",
       "      <td>0.081370</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.077354</td>\n",
       "      <td>0.086345</td>\n",
       "      <td>7.583889</td>\n",
       "      <td>1.445769</td>\n",
       "      <td>0.921769</td>\n",
       "      <td>1.535496</td>\n",
       "      <td>1.325261</td>\n",
       "      <td>1.260327</td>\n",
       "      <td>63.245958</td>\n",
       "      <td>10.765478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>0.029880</td>\n",
       "      <td>0.064183</td>\n",
       "      <td>57.787143</td>\n",
       "      <td>12.111429</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.179540</td>\n",
       "      <td>0.194743</td>\n",
       "      <td>0.204129</td>\n",
       "      <td>84.295000</td>\n",
       "      <td>16.102857</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.263643</td>\n",
       "      <td>0.232971</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.262143</td>\n",
       "      <td>90.917143</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>45.300000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.250000</td>\n",
       "      <td>0.319971</td>\n",
       "      <td>0.293929</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.325150</td>\n",
       "      <td>94.563929</td>\n",
       "      <td>18.180357</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>11.655000</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>85.950000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.508357</td>\n",
       "      <td>0.454429</td>\n",
       "      <td>0.538314</td>\n",
       "      <td>0.546017</td>\n",
       "      <td>98.610000</td>\n",
       "      <td>20.461429</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>543.300000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weekofyear     ndvi_ne     ndvi_nw     ndvi_se     ndvi_sw  \\\n",
       "count  520.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    26.503846    0.263869    0.238783    0.250126    0.266779   \n",
       "std     15.029450    0.081370    0.076751    0.077354    0.086345   \n",
       "min      1.000000    0.061729    0.035860    0.029880    0.064183   \n",
       "25%     13.750000    0.200000    0.179540    0.194743    0.204129   \n",
       "50%     26.500000    0.263643    0.232971    0.249800    0.262143   \n",
       "75%     39.250000    0.319971    0.293929    0.302300    0.325150   \n",
       "max     53.000000    0.508357    0.454429    0.538314    0.546017   \n",
       "\n",
       "       reanalysis_relative_humidity_percent  \\\n",
       "count                            516.000000   \n",
       "mean                              88.639117   \n",
       "std                                7.583889   \n",
       "min                               57.787143   \n",
       "25%                               84.295000   \n",
       "50%                               90.917143   \n",
       "75%                               94.563929   \n",
       "max                               98.610000   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "count                             516.000000          483.000000   \n",
       "mean                               17.096110           27.530933   \n",
       "std                                 1.445769            0.921769   \n",
       "min                                12.111429           21.400000   \n",
       "25%                                16.102857           27.000000   \n",
       "50%                                17.428571           27.600000   \n",
       "75%                                18.180357           28.100000   \n",
       "max                                20.461429           30.800000   \n",
       "\n",
       "       station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "count               483.000000          506.000000          512.000000   \n",
       "mean                 10.566197           34.004545           21.196680   \n",
       "std                   1.535496            1.325261            1.260327   \n",
       "min                   5.200000           30.100000           14.700000   \n",
       "25%                   9.500000           33.200000           20.600000   \n",
       "50%                  10.625000           34.000000           21.300000   \n",
       "75%                  11.655000           34.900000           22.000000   \n",
       "max                  15.800000           42.200000           24.200000   \n",
       "\n",
       "       station_precip_mm  total_cases  \n",
       "count         504.000000   520.000000  \n",
       "mean           62.467262     7.565385  \n",
       "std            63.245958    10.765478  \n",
       "min             0.000000     0.000000  \n",
       "25%            17.200000     1.000000  \n",
       "50%            45.300000     5.000000  \n",
       "75%            85.950000     9.000000  \n",
       "max           543.300000   116.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import  mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "sj_new = pd.read_csv(\"./iq_less_columns.csv\")\n",
    "sj_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ca603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>0.183783</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.225129</td>\n",
       "      <td>0.150214</td>\n",
       "      <td>92.581429</td>\n",
       "      <td>17.654286</td>\n",
       "      <td>27.440</td>\n",
       "      <td>10.760</td>\n",
       "      <td>33.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>0.291657</td>\n",
       "      <td>0.272267</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.320914</td>\n",
       "      <td>83.885714</td>\n",
       "      <td>16.320000</td>\n",
       "      <td>27.025</td>\n",
       "      <td>9.625</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0.208543</td>\n",
       "      <td>0.366457</td>\n",
       "      <td>0.212629</td>\n",
       "      <td>0.255514</td>\n",
       "      <td>92.057143</td>\n",
       "      <td>18.030000</td>\n",
       "      <td>26.950</td>\n",
       "      <td>10.350</td>\n",
       "      <td>33.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.122057</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>88.970000</td>\n",
       "      <td>15.394286</td>\n",
       "      <td>26.900</td>\n",
       "      <td>9.700</td>\n",
       "      <td>33.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>0.306100</td>\n",
       "      <td>0.327683</td>\n",
       "      <td>0.250086</td>\n",
       "      <td>0.267914</td>\n",
       "      <td>78.610000</td>\n",
       "      <td>15.468571</td>\n",
       "      <td>27.050</td>\n",
       "      <td>11.850</td>\n",
       "      <td>33.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>22</td>\n",
       "      <td>0.301471</td>\n",
       "      <td>0.380029</td>\n",
       "      <td>0.280629</td>\n",
       "      <td>0.383186</td>\n",
       "      <td>89.990000</td>\n",
       "      <td>17.185714</td>\n",
       "      <td>27.400</td>\n",
       "      <td>9.050</td>\n",
       "      <td>32.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>23</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.296343</td>\n",
       "      <td>0.285371</td>\n",
       "      <td>0.350357</td>\n",
       "      <td>93.891429</td>\n",
       "      <td>17.448571</td>\n",
       "      <td>27.520</td>\n",
       "      <td>10.720</td>\n",
       "      <td>33.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>24</td>\n",
       "      <td>0.238729</td>\n",
       "      <td>0.251029</td>\n",
       "      <td>0.252586</td>\n",
       "      <td>0.249771</td>\n",
       "      <td>94.967143</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>27.200</td>\n",
       "      <td>10.075</td>\n",
       "      <td>32.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>25</td>\n",
       "      <td>0.310429</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.406614</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>89.057143</td>\n",
       "      <td>15.137143</td>\n",
       "      <td>26.700</td>\n",
       "      <td>8.480</td>\n",
       "      <td>32.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>26</td>\n",
       "      <td>0.339467</td>\n",
       "      <td>0.240071</td>\n",
       "      <td>0.356943</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>87.030000</td>\n",
       "      <td>16.148571</td>\n",
       "      <td>27.350</td>\n",
       "      <td>9.675</td>\n",
       "      <td>32.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     weekofyear   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0            26  0.183783  0.142500  0.225129  0.150214   \n",
       "1            27  0.291657  0.272267  0.330700  0.320914   \n",
       "2            28  0.208543  0.366457  0.212629  0.255514   \n",
       "3            29  0.089286  0.063214  0.122057  0.081957   \n",
       "4            30  0.306100  0.327683  0.250086  0.267914   \n",
       "..          ...       ...       ...       ...       ...   \n",
       "151          22  0.301471  0.380029  0.280629  0.383186   \n",
       "152          23  0.247600  0.296343  0.285371  0.350357   \n",
       "153          24  0.238729  0.251029  0.252586  0.249771   \n",
       "154          25  0.310429  0.302700  0.406614  0.403943   \n",
       "155          26  0.339467  0.240071  0.356943  0.273600   \n",
       "\n",
       "     reanalysis_relative_humidity_percent  \\\n",
       "0                               92.581429   \n",
       "1                               83.885714   \n",
       "2                               92.057143   \n",
       "3                               88.970000   \n",
       "4                               78.610000   \n",
       "..                                    ...   \n",
       "151                             89.990000   \n",
       "152                             93.891429   \n",
       "153                             94.967143   \n",
       "154                             89.057143   \n",
       "155                             87.030000   \n",
       "\n",
       "     reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "0                                17.654286              27.440   \n",
       "1                                16.320000              27.025   \n",
       "2                                18.030000              26.950   \n",
       "3                                15.394286              26.900   \n",
       "4                                15.468571              27.050   \n",
       "..                                     ...                 ...   \n",
       "151                              17.185714              27.400   \n",
       "152                              17.448571              27.520   \n",
       "153                              16.410000              27.200   \n",
       "154                              15.137143              26.700   \n",
       "155                              16.148571              27.350   \n",
       "\n",
       "     station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "0                     10.760                33.8                21.5   \n",
       "1                      9.625                33.0                21.2   \n",
       "2                     10.350                33.4                21.6   \n",
       "3                      9.700                33.3                14.2   \n",
       "4                     11.850                33.5                16.9   \n",
       "..                       ...                 ...                 ...   \n",
       "151                    9.050                32.6                21.8   \n",
       "152                   10.720                33.8                21.4   \n",
       "153                   10.075                32.6                21.6   \n",
       "154                    8.480                32.2                21.8   \n",
       "155                    9.675                32.6                22.0   \n",
       "\n",
       "     station_precip_mm  \n",
       "0                 11.2  \n",
       "1                  8.9  \n",
       "2                 22.6  \n",
       "3                  4.8  \n",
       "4                  3.0  \n",
       "..                 ...  \n",
       "151               33.0  \n",
       "152               68.0  \n",
       "153               93.2  \n",
       "154               34.1  \n",
       "155               14.9  \n",
       "\n",
       "[156 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test = pd.read_csv(\"./iq_test_less_columns.csv\")\n",
    "Year = sj_test['year']\n",
    "sj_test.drop(['year'], axis=1, inplace=True)\n",
    "sj_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e4a72-d0d4-4b20-b911-3eaf4ead3d10",
   "metadata": {},
   "source": [
    "The following cell replaces the NaN values with the mean of the cells' values above and below the cell with NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a38738-3fa4-4569-b3cb-b43f6954b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 'df' is a dataframe containing NaN values in multiple columns\n",
    "for col in sj_new.columns:\n",
    "    temp = sj_new[col].to_numpy()  # convert the column to a numpy array for faster processing\n",
    "    \n",
    "    # fill NaN values with the mean of the previous and next valid values\n",
    "    mask = sj_new[col].isnull()\n",
    "    temp[mask] = pd.Series(temp).fillna(method='ffill').add(pd.Series(temp).fillna(method='bfill')).div(2).values[mask]\n",
    "\n",
    "    # assign the updated values back to the dataframe column\n",
    "    sj_new[col] = pd.Series(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0221193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 'df' is a dataframe containing NaN values in multiple columns\n",
    "for col in sj_test.columns:\n",
    "    temp = sj_test[col].to_numpy()  # convert the column to a numpy array for faster processing\n",
    "    \n",
    "    # fill NaN values with the mean of the previous and next valid values\n",
    "    mask = sj_test[col].isnull()\n",
    "    temp[mask] = pd.Series(temp).fillna(method='ffill').add(pd.Series(temp).fillna(method='bfill')).div(2).values[mask]\n",
    "\n",
    "    # assign the updated values back to the dataframe column\n",
    "    sj_test[col] = pd.Series(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa8c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "threshold_prec = sj_new['station_precip_mm'].quantile(0.975)\n",
    "threshold_cases = sj_new['total_cases'].quantile(0.975)\n",
    "\n",
    "# Applying the thresholds into the df\n",
    "sj_new.loc[sj_new['station_precip_mm'] > threshold_prec, 'station_precip_mm'] = threshold_prec\n",
    "sj_new.loc[sj_new['total_cases'] > threshold_cases, 'total_cases'] = threshold_cases\n",
    "\n",
    "min_val = sj_new['total_cases'].min()\n",
    "max_val = sj_new['total_cases'].max()\n",
    "\n",
    "print(min_val)\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d824d4ed-3d41-4adc-9f0b-7668e03b391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_new['weekofyear'] =  sj_new['weekofyear'] / 53\n",
    "sj_new['reanalysis_relative_humidity_percent'] = sj_new['reanalysis_relative_humidity_percent'] / 100\n",
    "sj_new['reanalysis_specific_humidity_g_per_kg'] =  sj_new['reanalysis_specific_humidity_g_per_kg'] / 20\n",
    "\n",
    "# select columns to normalize with StandardScaler and MinMaxScaler\n",
    "#columns_minmax = ['station_precip_mm', 'total_cases']\n",
    "columns_standard = ['station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c', 'station_min_temp_c']\n",
    "\n",
    "# normalize columns with StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_standard.fit(sj_new[columns_standard])\n",
    "\n",
    "sj_new[columns_standard] = scaler_standard.transform(sj_new[columns_standard])\n",
    "# normalize columns with MinMaxScaler\n",
    "scaler_minmax1 = MinMaxScaler()\n",
    "scaler_minmax2 = MinMaxScaler()\n",
    "\n",
    "scaler_minmax1.fit(sj_new[['station_precip_mm']])\n",
    "scaler_minmax2.fit(sj_new[['total_cases']])\n",
    "\n",
    "sj_new['station_precip_mm'] = scaler_minmax1.transform(sj_new[['station_precip_mm']])\n",
    "sj_new['total_cases'] = scaler_minmax2.transform(sj_new[['total_cases']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba7daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d466433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the thresholds into the df\n",
    "sj_test.loc[sj_test['station_precip_mm'] > threshold_prec, 'station_precip_mm'] = threshold_prec\n",
    "\n",
    "sj_test['weekofyear'] =  sj_test['weekofyear'] / 53\n",
    "sj_test['reanalysis_relative_humidity_percent'] = sj_test['reanalysis_relative_humidity_percent'] / 100\n",
    "sj_test['reanalysis_specific_humidity_g_per_kg'] =  sj_test['reanalysis_specific_humidity_g_per_kg'] / 20\n",
    "\n",
    "\n",
    "\n",
    "# select columns to normalize with StandardScaler and MinMaxScaler\n",
    "columns_minmax = ['station_precip_mm']\n",
    "columns_standard = ['station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c', 'station_min_temp_c']\n",
    "\n",
    "# normalize columns with StandardScaler\n",
    "\n",
    "sj_test[columns_standard] = scaler_standard.transform(sj_test[columns_standard])\n",
    "\n",
    "sj_test['station_precip_mm'] = scaler_minmax1.transform(sj_test[['station_precip_mm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352f3076-6aea-4998-b217-48d9bfc66fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.496855</td>\n",
       "      <td>0.266889</td>\n",
       "      <td>0.270574</td>\n",
       "      <td>0.258583</td>\n",
       "      <td>0.282235</td>\n",
       "      <td>0.896060</td>\n",
       "      <td>0.860718</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.129944</td>\n",
       "      <td>-0.005121</td>\n",
       "      <td>-0.095559</td>\n",
       "      <td>0.143862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281431</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>0.078552</td>\n",
       "      <td>0.071372</td>\n",
       "      <td>0.084310</td>\n",
       "      <td>0.066551</td>\n",
       "      <td>0.064270</td>\n",
       "      <td>0.846320</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.983621</td>\n",
       "      <td>1.020211</td>\n",
       "      <td>0.135253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.098257</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.686857</td>\n",
       "      <td>-2.952334</td>\n",
       "      <td>-2.658186</td>\n",
       "      <td>-3.283558</td>\n",
       "      <td>-5.559507</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.259434</td>\n",
       "      <td>0.214959</td>\n",
       "      <td>0.222436</td>\n",
       "      <td>0.211976</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.863164</td>\n",
       "      <td>0.816589</td>\n",
       "      <td>-0.570084</td>\n",
       "      <td>-0.530542</td>\n",
       "      <td>-0.582905</td>\n",
       "      <td>-0.480645</td>\n",
       "      <td>0.047245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.265229</td>\n",
       "      <td>0.269462</td>\n",
       "      <td>0.253164</td>\n",
       "      <td>0.281531</td>\n",
       "      <td>0.914114</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>-0.059010</td>\n",
       "      <td>0.069563</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>0.112114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.319236</td>\n",
       "      <td>0.324557</td>\n",
       "      <td>0.301639</td>\n",
       "      <td>0.347239</td>\n",
       "      <td>0.947425</td>\n",
       "      <td>0.908464</td>\n",
       "      <td>0.594796</td>\n",
       "      <td>0.766503</td>\n",
       "      <td>0.692403</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>0.185264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.429986</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.453043</td>\n",
       "      <td>0.529043</td>\n",
       "      <td>0.979829</td>\n",
       "      <td>0.979929</td>\n",
       "      <td>1.791907</td>\n",
       "      <td>2.759123</td>\n",
       "      <td>3.318037</td>\n",
       "      <td>1.582642</td>\n",
       "      <td>0.900308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weekofyear     ndvi_ne     ndvi_nw     ndvi_se     ndvi_sw  \\\n",
       "count  156.000000  156.000000  156.000000  156.000000  156.000000   \n",
       "mean     0.496855    0.266889    0.270574    0.258583    0.282235   \n",
       "std      0.281431    0.074686    0.078552    0.071372    0.084310   \n",
       "min      0.018868    0.089286    0.063214    0.098257    0.081957   \n",
       "25%      0.259434    0.214959    0.222436    0.211976    0.217500   \n",
       "50%      0.490566    0.265229    0.269462    0.253164    0.281531   \n",
       "75%      0.735849    0.319236    0.324557    0.301639    0.347239   \n",
       "max      0.981132    0.429986    0.464800    0.453043    0.529043   \n",
       "\n",
       "       reanalysis_relative_humidity_percent  \\\n",
       "count                            156.000000   \n",
       "mean                               0.896060   \n",
       "std                                0.066551   \n",
       "min                                0.663100   \n",
       "25%                                0.863164   \n",
       "50%                                0.914114   \n",
       "75%                                0.947425   \n",
       "max                                0.979829   \n",
       "\n",
       "       reanalysis_specific_humidity_g_per_kg  station_avg_temp_c  \\\n",
       "count                             156.000000          156.000000   \n",
       "mean                                0.860718            0.004875   \n",
       "std                                 0.064270            0.846320   \n",
       "min                                 0.686857           -2.952334   \n",
       "25%                                 0.816589           -0.570084   \n",
       "50%                                 0.877607           -0.059010   \n",
       "75%                                 0.908464            0.594796   \n",
       "max                                 0.979929            1.791907   \n",
       "\n",
       "       station_diur_temp_rng_c  station_max_temp_c  station_min_temp_c  \\\n",
       "count               156.000000          156.000000          156.000000   \n",
       "mean                  0.129944           -0.005121           -0.095559   \n",
       "std                   0.969496            0.983621            1.020211   \n",
       "min                  -2.658186           -3.283558           -5.559507   \n",
       "25%                  -0.530542           -0.582905           -0.480645   \n",
       "50%                   0.069563            0.017240           -0.004502   \n",
       "75%                   0.766503            0.692403            0.511320   \n",
       "max                   2.759123            3.318037            1.582642   \n",
       "\n",
       "       station_precip_mm  \n",
       "count         156.000000  \n",
       "mean            0.143862  \n",
       "std             0.135253  \n",
       "min             0.000000  \n",
       "25%             0.047245  \n",
       "50%             0.112114  \n",
       "75%             0.185264  \n",
       "max             0.900308  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd61483-9e35-4afe-9979-18e8fbb7c737",
   "metadata": {},
   "source": [
    "## Selecting target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d207ff6-a146-488c-ab8e-2bdd5bb0dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (520, 12)\n",
      "Shape of y_train: (520,)\n"
     ]
    }
   ],
   "source": [
    "X_sj = sj_new.drop(columns = \"total_cases\")\n",
    "Y_sj = sj_new.loc[:, \"total_cases\"]\n",
    "\n",
    "\n",
    "X_train = X_sj\n",
    "Y_train = Y_sj\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X_sj, Y_sj, test_size=0.20)\n",
    "print(\"Shape of x_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", Y_train.shape)\n",
    "# print(\"Shape of x_test:\", X_test.shape)\n",
    "# print(\"Shape of y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d70230-f564-4a30-9440-02f2463ee877",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Choice\n",
    "## Linear Model Regressor (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7649f147-8ad0-46b8-988c-a444328bcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.229\n",
      "MAE Train: 0.164\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train, Y_train)\n",
    "# lr_model_pred_test = lr_model.predict(X_test)\n",
    "lr_model_pred_train = lr_model.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "rmse_lr_train = mean_squared_error(Y_train, lr_model_pred_train, squared=False) \n",
    "mae_lr_train = mean_absolute_error(Y_train, lr_model_pred_train)\n",
    "\n",
    "# rmse_lr_test = mean_squared_error(Y_test, lr_model_pred_test, squared=False) \n",
    "# mae_lr_test = mean_absolute_error(Y_test, lr_model_pred_test)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_lr_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_lr_train))\n",
    "\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_lr_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_lr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a15a0-c515-43c2-97e1-fb6036cdd915",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce332567-6108-47fb-89c0-935ed731cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_model = DecisionTreeRegressor()\n",
    "# # create a grid search object\n",
    "\n",
    "# param_grid = {\n",
    "#     \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(dt_model, param_grid, cv=5)\n",
    "\n",
    "# # fit the grid search object to the training data\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # create a new random forest regressor with the best hyperparameters\n",
    "# dt_model = DecisionTreeRegressor(max_depth=best_params['max_depth'], criterion=best_params[\"criterion\"])\n",
    "\n",
    "# # fit the model to the training data\n",
    "# dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# # generate predictions on the training data\n",
    "# dt_train_pred = dt_model.predict(X_train)\n",
    "\n",
    "# # evaluate the model on the test data\n",
    "# dt_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# rmse_dt = mean_squared_error(Y_test, dt_test_pred, squared=False)\n",
    "# mae_dt = mean_absolute_error(Y_test, dt_test_pred)\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"RMSE: {:.3f}\".format(rmse_dt))\n",
    "# print(\"MAE: {:.3f}\".format(mae_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf9025d-0746-40b8-b64c-607ba203e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.239\n",
      "MAE Train: 0.172\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeRegressor(criterion='poisson', max_depth=5)\n",
    "\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# generate predictions on the training data\n",
    "dt_train_pred = dt_model.predict(X_train)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "# dt_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "rmse_dt_train = mean_squared_error(Y_train, dt_train_pred, squared=False)\n",
    "mae_dt_train = mean_absolute_error(Y_train, dt_train_pred)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_dt_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_dt_train))\n",
    "\n",
    "# rmse_dt_test = mean_squared_error(Y_test, dt_test_pred, squared=False)\n",
    "# mae_dt_test = mean_absolute_error(Y_test, dt_test_pred)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_dt_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_dt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884ad4b-89fa-4271-af1b-81275ddd4932",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bec2a96-c67b-4e0e-96e7-d262092ac9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a random forest regressor object\n",
    "# rf_model = RandomForestRegressor()\n",
    "\n",
    "# # define the grid search parameters\n",
    "# param_grid = {\n",
    "#     \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "\n",
    "# # create a grid search object\n",
    "# grid_search = GridSearchCV(rf_model, param_grid, cv=5)\n",
    "\n",
    "# # fit the grid search object to the training data\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # create a new random forest regressor with the best hyperparameters\n",
    "# rf_model = RandomForestRegressor(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], criterion=best_params[\"criterion\"])\n",
    "\n",
    "# # fit the model to the training data\n",
    "# rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# # generate predictions on the training data\n",
    "# rf_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# # evaluate the model on the test data\n",
    "# rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# rmse_rf = mean_squared_error(Y_test, rf_test_pred, squared=False)\n",
    "# mae_rf = mean_absolute_error(Y_test, rf_test_pred)\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"RMSE: {:.3f}\".format(rmse_rf))\n",
    "# print(\"MAE: {:.3f}\".format(mae_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d66d18-f993-4272-8a62-55d1fd8f3aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.082\n",
      "MAE Train: 0.059\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(criterion='squared_error', n_estimators=500, max_depth=15)\n",
    "# fit the model to the training data\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# generate predictions on the training data\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "# rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse_rf_train = mean_squared_error(Y_train, rf_train_pred, squared=False)\n",
    "mae_rf_train = mean_absolute_error(Y_train, rf_train_pred)\n",
    "\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_rf_train))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_rf_train))\n",
    "\n",
    "# rmse_rf_test = mean_squared_error(Y_test, rf_test_pred, squared=False)\n",
    "# mae_rf_test = mean_absolute_error(Y_test, rf_test_pred)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_rf_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e73762-58f9-4db8-9b55-37668cf45ab9",
   "metadata": {},
   "source": [
    "## Neural Network Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0ff8ebc-f302-4aa8-b58c-ebaf53f419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hyperparameters to search over\n",
    "# NN_model = MLPRegressor()\n",
    "# params = {\n",
    "#     'hidden_layer_sizes': [(64,), (32, 16), (64, 32, 16)],\n",
    "#     'max_iter': [500, 1000, 2000],\n",
    "#     'activation': ['relu', 'tanh', 'logistic']\n",
    "# }\n",
    "\n",
    "# # Perform a grid search over the hyperparameters\n",
    "# grid_search = GridSearchCV(NN_model, param_grid=params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Print the best hyperparameters and the associated mean test score\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# # Use the best model to make predictions on the training and testing data\n",
    "# best_model = grid_search.best_estimator_\n",
    "# Y_pred_train = best_model.predict(X_train)\n",
    "# Y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# # Compute the RMSE and MAE for the training and testing data\n",
    "# rmse_train = mean_squared_error(Y_train, Y_pred_train, squared=False)\n",
    "# mae_train = mean_absolute_error(Y_train, Y_pred_train)\n",
    "# print(\"RMSE Train: {:.3f}\".format(rmse_train))\n",
    "# print(\"MAE Train: {:.3f}\".format(mae_train))\n",
    "\n",
    "# rmse_test = mean_squared_error(Y_test, Y_pred_test, squared=False)\n",
    "# mae_test = mean_absolute_error(Y_test, Y_pred_test)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_test))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e80cda3c-f4f6-4c40-a52d-ed0f39b03d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.233\n",
      "MAE Train: 0.173\n"
     ]
    }
   ],
   "source": [
    "NN_model = MLPRegressor(activation='logistic', hidden_layer_sizes=(64), max_iter=2000)\n",
    "\n",
    "# Train the model on the training data\n",
    "NN_model.fit(X_train, Y_train)\n",
    "\n",
    "# Test the model on the testing data and print the accuracy score\n",
    "Y_pred_NN_train = NN_model.predict(X_train)\n",
    "# Y_pred_NN_test = NN_model.predict(X_test)\n",
    "\n",
    "rmse_train_nn = mean_squared_error(Y_train, Y_pred_NN_train, squared=False)\n",
    "mae_train_nn = mean_absolute_error(Y_train, Y_pred_NN_train)\n",
    "print(\"RMSE Train: {:.3f}\".format(rmse_train_nn))\n",
    "print(\"MAE Train: {:.3f}\".format(mae_train_nn))\n",
    "\n",
    "# rmse_test_nn = mean_squared_error(Y_test, Y_pred_NN_test, squared=False)\n",
    "# mae_test_nn = mean_absolute_error(Y_test, Y_pred_NN_test)\n",
    "# print(\"RMSE Test: {:.3f}\".format(rmse_test_nn))\n",
    "# print(\"MAE Test: {:.3f}\".format(mae_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d94370-14cc-46fe-af5b-857449e30bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 12))\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# ax.minorticks_on()\n",
    "# ax.xaxis.set_ticks_position(\"both\")\n",
    "# ax.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "# plt.title(\"Loss Curve\", fontsize=12)\n",
    "# plt.xlabel('Iterations', fontsize = 12)\n",
    "# plt.ylabel('Loss', fontsize = 12)\n",
    "# plt.plot(NN_model.loss_curve_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d33d32-335f-44b3-a9fa-39d7991a0b87",
   "metadata": {},
   "source": [
    "## eXtreme Gradient Boosting (XGB) Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cdadf69-804f-423f-97d6-6d5c32aef3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# #Define the XGBoost model\n",
    "# xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [3, 6, 9],\n",
    "#     'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb_model,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, Y_train, early_stopping_rounds=10, eval_set=[(X_test, Y_test)], verbose=False)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding RMSE\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# y_train_pred = grid_search.predict(X_train)\n",
    "# rmse_train = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "# print(f'RMSE_train: {rmse_train:.2f}')\n",
    "\n",
    "# test_predictions = grid_search.predict(X_test)\n",
    "# rmse_test = mean_squared_error(Y_test, test_predictions, squared=False)\n",
    "# print(f'RMSE_test: {rmse_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9962b871-3b16-4dbd-80ea-3640d4103335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.065\n",
      "MAE Train: 0.049\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, colsample_bytree = 0.5, max_depth=6)\n",
    "\n",
    "xgb_model.fit(X_train, Y_train, verbose=False)\n",
    "\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "rmse_train_xgb = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "mae_train_xgb = mean_absolute_error(Y_train, y_train_pred)\n",
    "print(f'RMSE Train: {rmse_train_xgb:.3f}')\n",
    "print(f'MAE Train: {mae_train_xgb:.3f}')\n",
    "\n",
    "# y_test_pred = xgb_model.predict(X_test)\n",
    "# rmse_test_xgb = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgb = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgb:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgb:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce63d4-97c2-4902-9ce2-e8dcac787ffe",
   "metadata": {},
   "source": [
    "# XGB with Regularization Regressor\n",
    "\n",
    "Uncommment the cell below to perform a gridsearch for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d3bcfae-b50d-479d-a5a4-a7aa192ca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'colsample_bytree': [0.5, 0.8],\n",
    "#     'max_depth': [4, 6, 8],\n",
    "#     'alpha': [0.1, 0.5],\n",
    "#     'min_child_weight': [1, 3],\n",
    "#     'gamma': [0.1, 0.5],\n",
    "#     'subsample': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Create the XGBoost regressor\n",
    "# xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best model from grid search\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Fit the best model to the training data\n",
    "# best_model.fit(X_train, Y_train, early_stopping_rounds=10, eval_set=[(X_test, Y_test)], verbose=False)\n",
    "\n",
    "# # Predict on training data\n",
    "# y_train_pred = best_model.predict(X_train)\n",
    "# rmse_train_xgbreg = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "# mae_train_xgbreg = mean_absolute_error(Y_train, y_train_pred)\n",
    "# print(f'RMSE Train: {rmse_train_xgbreg:.3f}')\n",
    "# print(f'MAE Train: {mae_train_xgbreg:.3f}')\n",
    "\n",
    "# # Predict on test data\n",
    "# y_test_pred = best_model.predict(X_test)\n",
    "# rmse_test_xgbreg = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgbreg = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgbreg:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgbreg:.3f}')\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b59dc35-dd9a-4ee3-8840-3b0f2f58449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.133\n",
      "MAE Train: 0.104\n"
     ]
    }
   ],
   "source": [
    "# Create the XGBoost regressor\n",
    "xgb_model_reg = xgb.XGBRegressor(alpha = 0.5, colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=8, min_child_weight=3, n_estimators=500, subsample=1.0)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "xgb_model_reg.fit(X_train, Y_train, verbose=False)\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = xgb_model_reg.predict(X_train)\n",
    "rmse_train_xgbreg = mean_squared_error(Y_train, y_train_pred, squared=False)\n",
    "mae_train_xgbreg = mean_absolute_error(Y_train, y_train_pred)\n",
    "print(f'RMSE Train: {rmse_train_xgbreg:.3f}')\n",
    "print(f'MAE Train: {mae_train_xgbreg:.3f}')\n",
    "\n",
    "# Predict on test data\n",
    "# y_test_pred = xgb_model.predict(X_test)\n",
    "# rmse_test_xgbreg = mean_squared_error(Y_test, y_test_pred, squared=False)\n",
    "# mae_test_xgbreg = mean_absolute_error(Y_test, y_test_pred)\n",
    "# print(f'RMSE Test: {rmse_test_xgbreg:.3f}')\n",
    "# print(f'MAE Test: {mae_test_xgbreg:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5ec48-b8c8-471a-867b-b5f9d98df9ed",
   "metadata": {},
   "source": [
    "# Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2ed0c-ceae-4ddd-a648-2ad3673d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the SVM model\n",
    "# from sklearn.svm import SVR\n",
    "# svm_model = SVR(kernel='rbf')\n",
    "\n",
    "# # Define the parameter grid for grid search\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'epsilon': [0.01, 0.1, 1]\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # Get the best model from grid search\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Train the model on the training data\n",
    "# best_model.fit(X_train, Y_train)\n",
    "\n",
    "# # Make predictions on the train set\n",
    "# y_pred = best_model.predict(X_train)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_train_svm = mean_absolute_error(Y_train, y_pred)\n",
    "\n",
    "# # Calculate the RMSE\n",
    "# rmse_train_svm = np.sqrt(mean_squared_error(Y_train, y_pred))\n",
    "\n",
    "# print(f'RMSE Train: {rmse_train_svm:.3f}')\n",
    "# print(f'MAE Train: {mae_train_svm:.3f}')\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_test_svm = mean_absolute_error(Y_test, test_predictions)\n",
    "\n",
    "# # Calculate the RMSE\n",
    "# rmse_test_svm = np.sqrt(mean_squared_error(Y_test, test_predictions))\n",
    "\n",
    "# print(f'RMSE Test: {rmse_test_svm:.3f}')\n",
    "# print(f'MAE Test: {mae_test_svm:.3f}')\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(\"Best parameters:\")\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca561f87-c62a-4731-81d3-2f3151d1cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.215\n",
      "MAE Train: 0.140\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = SVR(kernel='rbf', C=1, gamma='scale', epsilon=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the train set\n",
    "y_pred = svm_model.predict(X_train)\n",
    "\n",
    "# Calculate the MAE\n",
    "mae_train_svm = mean_absolute_error(Y_train, y_pred)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse_train_svm = np.sqrt(mean_squared_error(Y_train, y_pred))\n",
    "\n",
    "print(f'RMSE Train: {rmse_train_svm:.3f}')\n",
    "print(f'MAE Train: {mae_train_svm:.3f}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "# test_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# # Calculate the MAE\n",
    "# mae_test_svm = mean_absolute_error(Y_test, test_predictions)\n",
    "# # Calculate the RMSE\n",
    "# rmse_test_svm = np.sqrt(mean_squared_error(Y_test, test_predictions))\n",
    "\n",
    "# print(f'RMSE Test: {rmse_test_svm:.3f}')\n",
    "# print(f'MAE Test: {mae_test_svm:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594d536-7735-4d3b-930c-8174ee69c8ac",
   "metadata": {},
   "source": [
    "## Plotting of Top Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde06a7-0621-46f9-8299-cf650bd87694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_knn_train = 0.216\n",
    "# mae_knn_train = 0.1233\n",
    "# rmse_knn_test = 0.2129\n",
    "# mae_knn_test =  0.14107\n",
    "\n",
    "\n",
    "# rmse_adaboost_train = 0.2377\n",
    "# mae_adaboost_train = 0.1809\n",
    "# rmse_adaboost_test = 0.2094\n",
    "# mae_adaboost_test = 0.1629\n",
    "\n",
    "# rmse_train_values = [rmse_lr_train, rmse_dt_train, rmse_rf_train, rmse_train_nn, rmse_knn_train, rmse_adaboost_train, rmse_train_xgb, rmse_train_xgbreg, rmse_train_svm]\n",
    "# rmse_test_values = [rmse_lr_test, rmse_dt_test, rmse_rf_test, rmse_test_nn, rmse_knn_test, rmse_adaboost_test, rmse_test_xgb, rmse_test_xgbreg, rmse_test_svm]\n",
    "\n",
    "# mae_train_values = [mae_lr_train, mae_dt_train, mae_rf_train , mae_train_nn, mae_knn_train, mae_adaboost_train, mae_train_xgb, mae_train_xgbreg, mae_train_svm]\n",
    "# mae_test_values = [mae_lr_test, mae_dt_test, mae_rf_test , mae_test_nn, mae_knn_test, mae_adaboost_test, mae_test_xgb, mae_test_xgbreg, mae_test_svm]\n",
    "\n",
    "# model_labels = ['Linear Model', 'Decision Tree', 'Random Forest', 'Neural Network', 'Keras Nueral Network', \"Adaboost\", 'XGB', 'Reg. XGB', \"SVM\"]\n",
    "\n",
    "# train_positions = np.arange(len(model_labels))\n",
    "# test_positions = train_positions + 0.2  # Add a small offset to separate the bars\n",
    "\n",
    "# # Set the figure size\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# ax1 = plt.subplot(1, 2, 1)\n",
    "# ax1.bar(train_positions, rmse_train_values, color='lightcoral', width=0.2, label='Train');\n",
    "# ax1.bar(test_positions, rmse_test_values, color='firebrick', width=0.2, label='Test');\n",
    "# ax1.set_title('RMSE of Train and Test Sets', fontsize=12)\n",
    "# ax1.set_ylabel('RMSE', fontsize=12)\n",
    "# ax1.set_ylim(0,0.30)\n",
    "# ax1.set_xticks(train_positions + 0.1, model_labels, fontsize=12, rotation=45)\n",
    "# ax1.legend(loc=\"best\")\n",
    "# ax1.minorticks_on()\n",
    "# ax1.xaxis.set_ticks_position(\"both\")\n",
    "# ax1.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax1.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "\n",
    "# ax2 = plt.subplot(1, 2, 2)\n",
    "# ax2.bar(train_positions, mae_train_values, color='lightcoral', width=0.2, label='Train');\n",
    "# ax2.bar(test_positions, mae_test_values, color='firebrick', width=0.2, label='Test');\n",
    "# ax2.set_title('MAE of Train and Test Sets', fontsize=12)\n",
    "# ax2.set_ylabel('MAE', fontsize=12)\n",
    "# ax2.set_ylim(0,0.30)\n",
    "# ax2.set_xticks(train_positions + 0.1, model_labels, fontsize=12, rotation=45)\n",
    "# ax2.legend(loc=\"best\")\n",
    "# ax2.minorticks_on()\n",
    "# ax2.xaxis.set_ticks_position(\"both\")\n",
    "# ax2.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax2.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('iq_new_20.png')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39d673-84ac-4d10-baf0-02cfddabdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scatter plot of predicted vs actual values for test data\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# ax = plt.subplot(1, 1, 1)\n",
    "# plt.scatter(rf_test_pred, Y_test, color=\"blue\")\n",
    "\n",
    "# slope, intercept = np.polyfit(rf_test_pred, Y_test, 1)\n",
    "# x = np.linspace(min(rf_test_pred), max(rf_test_pred), 100)\n",
    "# y = slope * x + intercept\n",
    "\n",
    "# # create scatter plot of predicted vs actual values for test data\n",
    "# plt.scatter(rf_test_pred, Y_test, color = \"blue\")\n",
    "# plt.plot(x, y, color='red')\n",
    "\n",
    "# plt.title('Random Forest Regression Model', fontsize = 12)\n",
    "# plt.xlabel('Predicted Values', fontsize = 12)\n",
    "# plt.ylabel('Actual Values', fontsize = 12)\n",
    "\n",
    "# ax.minorticks_on()\n",
    "# ax.xaxis.set_ticks_position(\"both\")\n",
    "# ax.tick_params(top=True, right=True, which='major', direction='in', length=8, labelbottom=True, labeltop=False)\n",
    "# ax.tick_params(top=True, right=True, which='minor', direction='in', length=4)\n",
    "# plt.tight_layout()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min_val)\n",
    "# print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9fe1fc7f-91c4-4080-964c-c88e0f6eeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = svm_model.predict(sj_test)\n",
    "#predictions = xgb_model_reg.predict(sj_test)\n",
    "#predictions = xgb_model.predict(sj_test)\n",
    "#predictions = rf_model.predict(sj_test)\n",
    "#predictions = NN_model.predict(sj_test)\n",
    "#predictions = lr_model.predict(sj_test)\n",
    "predictions = dt_model.predict(sj_test)\n",
    "\n",
    "predictions = predictions * (max_val - min_val) + min_val\n",
    "predictions = predictions.astype(int)\n",
    "predictions[predictions < 0] = 0\n",
    "week = (sj_test['weekofyear']*53).astype(int)\n",
    "Year = Year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40f647a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions, columns=[\"total_cases\"])\n",
    "submission.insert(0, 'city', \"iq\")\n",
    "submission.insert(1, 'year', Year)\n",
    "submission.insert(2, 'weekofyear', week)\n",
    "submission.reset_index()\n",
    "submission.to_csv('iq_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8e4fc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear  total_cases\n",
       "0     iq  2010          26            7\n",
       "1     iq  2010          27            7\n",
       "2     iq  2010          28            7\n",
       "3     iq  2010          29            1\n",
       "4     iq  2010          30            1\n",
       "..   ...   ...         ...          ...\n",
       "151   iq  2013          22            7\n",
       "152   iq  2013          23            7\n",
       "153   iq  2013          24            7\n",
       "154   iq  2013          25            7\n",
       "155   iq  2013          26            7\n",
       "\n",
       "[156 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2c9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
